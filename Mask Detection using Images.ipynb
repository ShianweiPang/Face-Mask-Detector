{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choosing our Face Detection Model\n",
    "There are a lot of pretrained face detection models like Haar Cascades, Dlib Frontal Face Detector, MTCNN, and Caffe model using OpenCV's DNN Module. In this scenario, we are using Caffe Model.\n",
    "\n",
    "https://towardsdatascience.com/face-detection-models-which-to-use-and-why-d263e82c302c\n",
    "\n",
    "The above articles show that Caffe Model is the best model out of the other models mentioned above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up GPU-Enabled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "  except RuntimeError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Face Detector (Caffe Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "prototxtPath = os.getcwd()+r\"\\deploy.prototxt\"\n",
    "weightsPath = os.getcwd()+ r\"\\res10_300x300_ssd_iter_140000.caffemodel\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = cv2.dnn.readNet(prototxtPath, weightsPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the trained Face Mask Detection Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(os.getcwd()+r\"\\mobileNetV2_facemaskmodel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are taking its height and width only not taking its channel (RGB)\n",
    "image = cv2.imread(os.getcwd()+r\"\\4.jpg\")\n",
    "# print(image.shape)\n",
    "\n",
    "# Perform rescale of images if needed, comment below to remove rescaling \n",
    "scale_percent = 60 # percent of original size\n",
    "width = int(image.shape[1] * scale_percent / 100)\n",
    "height = int(image.shape[0] * scale_percent / 100)\n",
    "dim = (width, height)\n",
    "\n",
    "# # Include border for if necessary \n",
    "# colour = [255,255,255]\n",
    "# image= cv2.copyMakeBorder(image.copy(),100,100,75,75,cv2.BORDER_CONSTANT,value=colour)\n",
    "\n",
    "# resize image\n",
    "image = cv2.resize(cv2.resize(image, (300, 300)), dim, interpolation = cv2.INTER_AREA)\n",
    "(h,w) = image.shape[:2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob = cv2.dnn.blobFromImage(image,1.0, (300,300), (104.0, 177.0, 123.0),crop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3, 300, 300)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Mask Detection using Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using BlobFromImage to feed forward the image into the face detector to detect faces\n",
    "blob = cv2.dnn.blobFromImage(image,1.0, (300,300), (104.0, 177.0, 123.0),crop=False)\n",
    "net.setInput(blob)\n",
    "detections = net.forward()\n",
    "\n",
    "# for faces found in the images\n",
    "for i in range(0,detections.shape[2]):\n",
    "    confidence = detections[0,0,i,2]\n",
    "    \n",
    "    # if the confidence of the faces found is greater than 0.5, \n",
    "    # perform bounding boxes and include probability of 3 different classes \n",
    "    # Mask, No Mask, or Incorrect Mask\n",
    "    if confidence>0.5:\n",
    "\n",
    "        box = detections[0,0,i,3:7]*np.array([w,h,w,h])\n",
    "        (startX, startY, endX, endY) = box.astype('int')\n",
    "        \n",
    "        # ensure the bounding boxes fall wihtin the dimensions of the frame\n",
    "        (startX, startY) = (max(0,startX), max(0,startY))\n",
    "        (endX, endY) = (min(w-1,endX), min(h-1,endY))\n",
    "        \n",
    "        # extract the face Region of Interest, convert it from BGR to RGB channel\n",
    "        # resize it to 224, 224 because our model are using Tensor Input of size 224x224\n",
    "        face = image[startY:endY, startX:endX]\n",
    "        \n",
    "        # cvtc - convert colour\n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2RGB)\n",
    "        face = cv2.resize(face, (224,224))\n",
    "        \n",
    "        face = img_to_array(face)\n",
    "        face = preprocess_input(face)\n",
    "        face = np.expand_dims(face, axis=0)\n",
    "        \n",
    "        (correct_mask, incorrect_mask, no_mask) = model.predict(face)[0]\n",
    "        \n",
    "        # define the class label and color for the bounding boxes and text\n",
    "        # in our project we are using Mask, No, Mask and Incorrect Mask\n",
    "        index = (correct_mask, incorrect_mask, no_mask).index(max(correct_mask, incorrect_mask, no_mask))\n",
    "        if index==0:\n",
    "            label = \"Mask\"\n",
    "            color = (0,255,0)\n",
    "        elif index==1:\n",
    "            label = \"Incorrect Mask\"\n",
    "            color = (0,128,255)\n",
    "        elif index==2:\n",
    "            label = \"No mask\"\n",
    "            color = (0,0,255)\n",
    "        \n",
    "        # include probability and label for bounding boxes\n",
    "        label = label + \"{prob}\".format(prob = (max(correct_mask, incorrect_mask, no_mask)*100))\n",
    "        \n",
    "        # put the text and rectange in the image\n",
    "        cv2.putText(image,label,(startX,endY-10),cv2.FONT_HERSHEY_SIMPLEX, 0.45,color,2)\n",
    "        cv2.rectangle(image, (startX, startY), (endX,endY),color,2)\n",
    "\n",
    "        \n",
    "# show the image, until user press 0 or exit the window\n",
    "cv2.imshow(\"Output\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9918007"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detections[0,0,1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
